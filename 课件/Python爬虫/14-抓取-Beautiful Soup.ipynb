{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Beautiful Soup\n",
    "是一个非常流行 的 Python 模块。该模块可以解析网页 ，\n",
    "并提供定位内容的便捷接口。如果你还没有安装该模块，可以使用下面的命令# 安装其最新版本\n",
    "pip install beautifulsoup4\n",
    "\n",
    "使用 Beautiful Soup的第一步是将己下载的HTML内容解析为soup 文档 。\n",
    "由于大多数网页都不具备良好的HTML 格式 ，因此Beautiful Soup 需要对其\n",
    "实际格式进行确定\n",
    "\n",
    "例如 ，在下面这个简单网页的列表中，存在属性值两侧\n",
    "引号缺失和标签未闭含的问题。\n",
    "\n",
    "<ul class=country>\n",
    "<li>Area</li>\n",
    "<li>Population\n",
    "</ul>\n",
    "\n",
    "如果 Population 列表项被解析为 Area 列表项的子元素，而不是并列\n",
    "的两个列表项的话 ， 我们在抓取时就会得到错误的结果。 下面让我们看一下\n",
    "Beautiful Soup 是如何处理的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"country\">\n",
      " <li>\n",
      "  Area\n",
      " </li>\n",
      " <li>\n",
      "  Population\n",
      " </li>\n",
      "</ul>\n",
      "<ul class=\"country\"> <li>Area</li> <li>Population</li></ul>\n",
      "<li>Area</li>\n",
      "[<li>Area</li>, <li>Population</li>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import  BeautifulSoup\n",
    "broken_html ='<ul class=country> <li>Area</li> <li>Population</ul>'\n",
    "soup = BeautifulSoup(broken_html,'html.parser')\n",
    "fixed_html = soup.prettify()\n",
    "\n",
    "print(fixed_html)\n",
    "\n",
    "# BeautifulSoup 能够正确解析缺失的引号并闭合标签\n",
    "\n",
    "# 现在可以使用 find()和 findall()方法来定位我们需要的元素了 。\n",
    "ul = soup.find('ul',attrs={'class':'country'})\n",
    "print(ul)\n",
    "print(ul.find('li'))#只返回第一个\n",
    "print(ul.find_all('li'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽取示例网站国家面积数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1127127 square kilometres\n"
     ]
    }
   ],
   "source": [
    "from  bs4 import  BeautifulSoup\n",
    "import  requests\n",
    "url = 'http://example.webscraping.com/places/default/view/Ethiopia-71'\n",
    "html =requests.get(url)# 最基本的GET请求\n",
    "soup = BeautifulSoup(html.text,'html.parser')\n",
    "tr = soup.find(attrs={'id':'places_area__row'})\n",
    "td = tr.find(attrs={'class':'w2p_fw'})\n",
    "area = td.text\n",
    "print(area)\n",
    "\n",
    "# 这段代码虽然比正则表达式的代码更加复杂 ， 但更容易构造和理解。而且 ，\n",
    "# 像多余的空格和标签属性这种布局上的小变化 , 我们也无须再担心了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
